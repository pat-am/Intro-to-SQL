{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/group-by-having-count).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nQueries with **GROUP BY** can be powerful. There are many small things that can trip you up (like the order of the clauses), but it will start to feel natural once you've done it a few times. Here, you'll write queries using **GROUP BY** to answer questions from the Hacker News dataset.\n\nBefore you get started, run the following cell to set everything up:","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex3 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:35.314216Z","iopub.execute_input":"2022-03-29T13:40:35.314825Z","iopub.status.idle":"2022-03-29T13:40:39.30623Z","shell.execute_reply.started":"2022-03-29T13:40:35.314716Z","shell.execute_reply":"2022-03-29T13:40:39.305051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code cell below fetches the `comments` table from the `hacker_news` dataset.  We also preview the first five rows of the table.","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"hacker_news\" dataset\ndataset_ref = client.dataset(\"hacker_news\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)\n\n# Construct a reference to the \"comments\" table\ntable_ref = dataset_ref.table(\"comments\")\n\n# API request - fetch the table\ntable = client.get_table(table_ref)\n\n# Preview the first five lines of the \"comments\" table\nclient.list_rows(table, max_results=5).to_dataframe()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:40:45.70147Z","iopub.execute_input":"2022-03-29T13:40:45.701786Z","iopub.status.idle":"2022-03-29T13:40:47.645865Z","shell.execute_reply.started":"2022-03-29T13:40:45.701754Z","shell.execute_reply":"2022-03-29T13:40:47.644987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) Prolific commenters\n\nHacker News would like to send awards to everyone who has written more than 10,000 posts. Write a query that returns all authors with more than 10,000 posts as well as their post counts. Call the column with post counts `NumPosts`.\n\nIn case sample query is helpful, here is a query you saw in the tutorial to answer a similar question:\n```\nquery = \"\"\"\n        SELECT parent, COUNT(1) AS NumPosts\n        FROM `bigquery-public-data.hacker_news.comments`\n        GROUP BY parent\n        HAVING COUNT(1) > 10\n        \"\"\"\n```","metadata":{}},{"cell_type":"code","source":"# Query to select prolific commenters and post counts\nprolific_commenters_query = \"\"\"\nSELECT author, COUNT(id) AS NumPosts\nFROM `bigquery-public-data.hacker_news.comments`\nGROUP BY author\nHAVING COUNT(id) > 10000\n\"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(prolific_commenters_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nprolific_commenters = query_job.to_dataframe()\n\n# View top few rows of results\nprint(prolific_commenters.head())\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:46:41.653825Z","iopub.execute_input":"2022-03-29T13:46:41.654104Z","iopub.status.idle":"2022-03-29T13:46:43.87231Z","shell.execute_reply.started":"2022-03-29T13:46:41.654071Z","shell.execute_reply":"2022-03-29T13:46:43.871305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Deleted comments\n\nHow many comments have been deleted? (If a comment was deleted, the `deleted` column in the comments table will have the value `True`.)","metadata":{}},{"cell_type":"code","source":"deleted_comments_query = \"\"\"\nSELECT COUNT(deleted) AS DeletedComms\nFROM `bigquery-public-data.hacker_news.comments`\nWHERE deleted = True\n\"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquery_job = client.query(deleted_comments_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\ndeleted_comments = query_job.to_dataframe()\n\n# View top few rows of results\nprint(deleted_comments.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:52:30.062222Z","iopub.execute_input":"2022-03-29T13:52:30.062587Z","iopub.status.idle":"2022-03-29T13:52:31.766583Z","shell.execute_reply.started":"2022-03-29T13:52:30.062548Z","shell.execute_reply":"2022-03-29T13:52:31.765721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_deleted_posts = 227736 # Put your answer here\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T13:52:43.74825Z","iopub.execute_input":"2022-03-29T13:52:43.748962Z","iopub.status.idle":"2022-03-29T13:52:43.757722Z","shell.execute_reply.started":"2022-03-29T13:52:43.748909Z","shell.execute_reply":"2022-03-29T13:52:43.757077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the solution, uncomment the line below.","metadata":{}},{"cell_type":"code","source":"#q_2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keep Going\n**[Click here](https://www.kaggle.com/dansbecker/order-by)** to move on and learn about the **ORDER BY** clause.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*","metadata":{}}]}